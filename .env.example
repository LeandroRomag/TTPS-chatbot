# Copia este archivo como ".env" en la raíz del proyecto y completa los valores necesarios.
# Este proyecto usa Groq como único backend para el LLM.

# --- Credenciales Groq (OBLIGATORIO) ---
# Obtén tu API key en: https://console.groq.com/
GROQ_API_KEY=tu_api_key_de_groq

# Modelo recomendado (puedes cambiarlo por otro disponible en Groq)
GROQ_MODEL=llama-3.1-8b-instant

# Parámetros de generación (ajústalos si necesitas)
GROQ_TEMPERATURE=0.2
GROQ_MAX_TOKENS=512

# Manejo de rate limit y errores transitorios
# Reintentos automáticos con backoff exponencial
GROQ_MAX_RETRIES=3
GROQ_BACKOFF_BASE=0.5

# --- Configuración RAG (chunking, recuperación y tamaño del contexto) ---
# Tamaño de chunk en palabras y solapamiento
RAG_CHUNK_SIZE=500
RAG_CHUNK_OVERLAP=80

# Límite por chunk (caracteres) para evitar trozos muy grandes
RAG_PER_CHUNK_MAX_CHARS=1600

# Cuántos chunks intentar recuperar (BM25)
RAG_TOP_K=10

# Máximo de caracteres a enviar como contexto al LLM (total)
RAG_CONTEXT_CHARS=20000

# WhatsApp Business API
WHATSAPP_TOKEN=tu_token_de_whatsapp_aqui
PHONE_NUMBER_ID=tu_phone_number_id_aqui

# Para testing (opcional)
TEST_WHATSAPP_NUMBER=5412345678XX




